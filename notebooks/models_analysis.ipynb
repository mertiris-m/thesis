{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d59b4229",
   "metadata": {},
   "source": [
    "# QM9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071c1846",
   "metadata": {},
   "source": [
    "## GCNConv & CINEConv model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0422a891",
   "metadata": {},
   "source": [
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f19892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.0+cu126\n",
      "Using device: cpu\n",
      "----- Baseline GCN Model Architecture -----\n",
      "GCN_baseline(\n",
      "  (conv1): GCNConv(14, 128)\n",
      "  (conv2): GCNConv(128, 128)\n",
      "  (fc_block): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Model created successfully and ready to be used.\n",
      "----- GINE Model Architecture -----\n",
      "GINE(\n",
      "  (conv1): GINEConv(nn=Sequential(\n",
      "    (0): Linear(in_features=14, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  ))\n",
      "  (conv2): GINEConv(nn=Sequential(\n",
      "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  ))\n",
      "  (fc_block): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Model created successfully and ready to be used.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "root = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "qm9_path = root / 'data' / 'QM9' / 'dsgdb9nsd.xyz'\n",
    "qm9_edit_dir = root / 'data' / 'QM9_edit'\n",
    "qm9_csv_path = qm9_edit_dir / 'QM9_edit.csv'\n",
    "qm9_dataset_path = qm9_edit_dir / 'qm9_dataset.pt'\n",
    "models_dir = root / 'models'\n",
    "results_dir = root / 'results'\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "os.chdir(root)\n",
    "\n",
    "from src.models.gcn_baseline import GCN_baseline\n",
    "from src.models.gine import GINE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fa0951",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3d0d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Dataset Path: /home/pc/Python_Projects/thesis/data/QM9_edit/qm9_dataset.pt\n"
     ]
    }
   ],
   "source": [
    "ROOT_DIR = root # Assumes running from project root\n",
    "DATASET_PATH = qm9_dataset_path\n",
    "SCALER_DIR = qm9_edit_dir\n",
    "PROPERTY_NAMES = ['Dipole_moment', 'U', 'Cv']\n",
    "\n",
    "# Training Hyperparameters\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 500 # Large since there will be early stopping\n",
    "HIDDEN_DIM = 128\n",
    "DROPOUT_RATE = 0.2\n",
    "SPLIT_RATIOS = [0.8, 0.1, 0.1] # Train, Validation, Test\n",
    "\n",
    "# Plotting Style\n",
    "plt.style.use('seaborn-v0_8-paper')\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Dataset Path: {DATASET_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91195df2",
   "metadata": {},
   "source": [
    "### Data loading and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbb1b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loading...\n",
      "Dataset loaded with 133885 total graphs.\n",
      "Train samples: 107108, Validation samples: 13388, Test samples: 13389\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "print(\"Dataset loading...\")\n",
    "full_dataset = torch.load(DATASET_PATH, weights_only=False)\n",
    "print(f\"Dataset loaded with {len(full_dataset)} total graphs.\")\n",
    "\n",
    "# Determine feature sizes from the first graph\n",
    "first_graph = full_dataset[0]\n",
    "num_node_features = first_graph.num_node_features\n",
    "num_edge_features = first_graph.num_edge_features\n",
    "num_properties = first_graph.y.shape[1]\n",
    "\n",
    "# Split Train, Validation and Test sets\n",
    "train_size = int(SPLIT_RATIOS[0] * len(full_dataset))\n",
    "val_size = int(SPLIT_RATIOS[1] * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    full_dataset, [train_size, val_size, test_size], generator=generator\n",
    ")\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}, Validation samples: {len(val_dataset)}, Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9709413",
   "metadata": {},
   "source": [
    "### Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961bd0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, loss_fn, device):\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = loss_fn(outputs, data.y)\n",
    "        loss.backward()\n",
    "        total_loss += loss.item() * data.num_graphs # loss.item() is the average loss for the batch * number of graphs on batch\n",
    "        optimizer.step()\n",
    "    return total_loss / len(dataloader.dataset) # the total average loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, dataloader, loss_fn, device):\n",
    "\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        data = data.to(device)\n",
    "        outputs = model(data)\n",
    "        loss = loss_fn(outputs, data.y)\n",
    "        total_loss += loss.item() * data.num_graphs \n",
    "    return total_loss / len(dataloader.dataset) \n",
    "\n",
    "def run_training_with_early_stopping(model, model_name, train_loader, val_loader, epochs, lr, device, patience=15):\n",
    "    \"\"\"\n",
    "    Runs the training process with early stopping.\n",
    "    \"\"\"\n",
    "\n",
    "    if patience < 1:\n",
    "            raise ValueError(\"Argument patience should be positive integer.\")\n",
    "    \n",
    "    print(f\"\\n----- Training {model_name} with Early Stopping (Patience={patience}) -----\")\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    \n",
    "    best_val_error = None\n",
    "    patience_counter = 0 # Initialize patience counter\n",
    "    \n",
    "    # Keep history for plotting\n",
    "    history = {'loss': [], 'val_error': []}\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        loss = train(model, train_loader, optimizer, loss_fn, device)\n",
    "        val_error  = test(model, val_loader, loss_fn, device)\n",
    "        \n",
    "        history['loss'].append(loss)\n",
    "        history['val_error'].append(val_error)\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == 1:\n",
    "             print(f\"Epoch {epoch:03d} | Train Loss: {loss:.6f} | Val Error: {val_error:.6f}\")\n",
    "\n",
    "        if best_val_error is None or val_error <= best_val_error:\n",
    "            best_val_error = val_error \n",
    "            patience_counter = 0 # Reset counter on improvement\n",
    "            # Save the best model\n",
    "            torch.save(model.state_dict(), f'models/{model_name}_best.pt')\n",
    "        else:\n",
    "            patience_counter += 1 # Increment counter if no improvement\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"--- Early stopping triggered at epoch {epoch} ---\")\n",
    "            break\n",
    "    \n",
    "    print(f\"----- Finished training {model_name}. Best Val Error: {best_val_error:.6f} -----\")\n",
    "    \n",
    "    # Return the trained model and the history for plotting\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f07cb4",
   "metadata": {},
   "source": [
    "### Training the baseline GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c621de",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_baseline_model = GCN_baseline(\n",
    "    node_features=num_node_features,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    output_dim=num_properties,\n",
    "    dropout_rate=DROPOUT_RATE\n",
    ").to(DEVICE)\n",
    "\n",
    "trained_gcn_model, gcn_history = run_training_with_early_stopping(\n",
    "    gcn_baseline_model, \"GCN Baseline\", train_loader, val_loader, EPOCHS, LEARNING_RATE, DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d59391",
   "metadata": {},
   "source": [
    "### Training the GINE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e137a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gine_model = GINE(\n",
    "    node_features=num_node_features,\n",
    "    edge_features=num_edge_features,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    output_dim=num_properties,\n",
    "    dropout_rate=DROPOUT_RATE\n",
    ").to(DEVICE)\n",
    "\n",
    "trained_gine_model, gine_history = run_training_with_early_stopping(\n",
    "    gine_model, \"GINE\", train_loader, val_loader, EPOCHS, LEARNING_RATE, DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7447277",
   "metadata": {},
   "source": [
    "### Evaluate and History plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f93262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- These were made with A.I. -----------\n",
    "\n",
    "def evaluate_and_plot(model, model_name, loader, device, scalers, prop_names):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_true = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            preds = model(data)\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_true.append(data.y.cpu().numpy())\n",
    "            \n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_true = np.concatenate(all_true, axis=0)\n",
    "    \n",
    "    # --- Inverse transform to get results in original units ---\n",
    "    unscaled_preds = np.zeros_like(all_preds)\n",
    "    unscaled_true = np.zeros_like(all_true)\n",
    "    \n",
    "    print(f\"\\n----- Results for {model_name} -----\")\n",
    "    for i, name in enumerate(prop_names):\n",
    "        scaler = scalers[name]\n",
    "        # Reshape for scaler which expects 2D array\n",
    "        unscaled_preds[:, i] = scaler.inverse_transform(all_preds[:, i].reshape(-1, 1)).flatten()\n",
    "        unscaled_true[:, i] = scaler.inverse_transform(all_true[:, i].reshape(-1, 1)).flatten()\n",
    "        \n",
    "        mse = mean_squared_error(unscaled_true[:, i], unscaled_preds[:, i])\n",
    "        print(f\"  - {name} MSE: {mse:.4f}\")\n",
    "        \n",
    "    # --- Plotting ---\n",
    "    fig, axes = plt.subplots(1, len(prop_names), figsize=(18, 5))\n",
    "    fig.suptitle(f'{model_name}: True vs. Predicted Values', fontsize=16)\n",
    "    \n",
    "    for i, (ax, name) in enumerate(zip(axes, prop_names)):\n",
    "        ax.scatter(unscaled_true[:, i], unscaled_preds[:, i], alpha=0.3, s=10)\n",
    "        \n",
    "        # Add a y=x line for reference\n",
    "        limits = [\n",
    "            min(ax.get_xlim()[0], ax.get_ylim()[0]),\n",
    "            max(ax.get_xlim()[1], ax.get_ylim()[1]),\n",
    "        ]\n",
    "        ax.plot(limits, limits, color='red', linestyle='--', label='Perfect Prediction')\n",
    "        \n",
    "        ax.set_xlabel(f\"True {name}\")\n",
    "        ax.set_ylabel(f\"Predicted {name}\")\n",
    "        ax.set_title(name)\n",
    "        ax.grid(True, linestyle='--', alpha=0.6)\n",
    "        ax.legend()\n",
    "        \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_training_history(history, model_name):\n",
    "    \"\"\"\n",
    "    Plots the training and validation loss curves from a history dictionary.\n",
    "    \"\"\"\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    # Plot training and validation loss\n",
    "    ax.plot(epochs, history['train_loss'], 'o-', label='Training Loss', alpha=0.8)\n",
    "    ax.plot(epochs, history['val_loss'], 'o-', label='Validation Loss', alpha=0.8)\n",
    "    \n",
    "    # Find the epoch with the best validation loss for annotation\n",
    "    best_val_epoch = np.argmin(history['val_loss']) + 1\n",
    "    best_val_loss = np.min(history['val_loss'])\n",
    "    \n",
    "    # Add a vertical line and annotation for the best epoch\n",
    "    ax.axvline(best_val_epoch, color='red', linestyle='--', lw=1, label=f'Best Epoch ({best_val_epoch})')\n",
    "    ax.annotate(f'Best Val Loss: {best_val_loss:.4f}',\n",
    "                xy=(best_val_epoch, best_val_loss),\n",
    "                xytext=(best_val_epoch + 5, best_val_loss + 0.05 * best_val_loss), # Offset for readability\n",
    "                arrowprops=dict(facecolor='black', shrink=0.05, width=1, headwidth=8),\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"black\", lw=1, alpha=0.7))\n",
    "\n",
    "    # Formatting\n",
    "    ax.set_title(f'{model_name}: Training and Validation Loss', fontsize=16)\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Loss (MSE)')\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax.legend()\n",
    "    \n",
    "    # Ensure y-axis starts from a reasonable place if losses are small\n",
    "    ax.set_ylim(bottom=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbd9c0c",
   "metadata": {},
   "source": [
    "### Run evaluate and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7a0ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = {}\n",
    "for name in PROPERTY_NAMES:\n",
    "    scaler_path = os.path.join(SCALER_DIR, f'{name}_QM9_scaler.pkl')\n",
    "    scalers[name] = joblib.load(scaler_path)\n",
    "    \n",
    "# # Evaluate the GCN Baseline model\n",
    "# evaluate_and_plot(trained_gcn_model, \"GCN Baseline\", test_loader, DEVICE, scalers, PROPERTY_NAMES)\n",
    "\n",
    "# Evaluate the GINE model\n",
    "evaluate_and_plot(trained_gine_model, \"GINE Model\", test_loader, DEVICE, scalers, PROPERTY_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea66294",
   "metadata": {},
   "source": [
    "### Run History plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ce3b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_training_history(gcn_history, \"GCN Baseline\")\n",
    "\n",
    "plot_training_history(gine_history, \"GINE Model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
